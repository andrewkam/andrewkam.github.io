<!doctype html>
<html lang="en-US">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Laugh Track Synth</title>
<link href="css/singlePageTemplate.css" rel="stylesheet" type="text/css">
<style type="text/css">
a:link {
	color: #0568F2;
	text-decoration: none;
}
a:visited {
	color: #A849E9;
	text-decoration: none;
}
a:hover {
	text-decoration: none;
}
a:active {
	text-decoration: none;
}
</style>
<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script>
<script src="http://use.edgefonts.net/source-sans-pro:n2:default.js" type="text/javascript"></script>
<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>
<body>
<!-- Main Container -->

<div class="container"> <!-- Navigation -->
  <!-- Hero Section -->
  <section class="hero" id="hero">
    <h2 class="hero_header">Laugh Track Synth</h2><br>
    <h4 class="hero_header">Andrew Kam</h4>
    <h4 class="hero_header">MUMT 307 - Winter 2018</h4>
  </section>
  <!-- About Section -->
  <!-- Stats Gallery Section -->
  
  
  <section class="about" id="about">
    <h2>History</h2>
    <ul>
    	<p>A laugh track, invented by American sound engineer Charles Douglass, is a separate soundtrack for a recorded comedy show containing the sound of audience laughter. During tapings of early radio and television shows, the performances of the actors and crew could be controlled, but live audiences could not be relied upon to laugh at the correct moments. Douglass extracted laughter and applause from live soundtracks recorded, and then placed the recorded sounds into a tape machine known as the "laff box". Douglass used a keyboard to select the style, gender and age of the laugh as well as a foot pedal to time the length of the reaction. Inside the machine were 320 different laughs on 32 tape loops, 10 to a loop. Since the tapes were looped, laughs were played in the same order repeatedly.</p>
   	  <img src="images/laffbox1.jpg" width="468" height="640" alt=""/>
   	  <img src="images/laffbox2.jpg" width="480" height="640" alt=""/>
    </ul>
    <h2>Purpose</h2>
    <ul>
    	<p>My project is intended to replicate the overall sound of a laugh track, but using only a single recording of my voice. Such a tool could be useful for production effects in both music and sound, as it would construct the sound of a crowd of unsynchronized voices.</p>
    </ul>
    <h2>Tools</h2>
    <ul>
		<li>Audacity</li>
   		<li>MATLAB</li>
    </ul>
    <h2>Design</h2>
    <ul>
      <h3>Recording</h3>
      <p>The recording of a single laugh stream is completed using Audacity, as only a clean version of a laugh is required, with no effects. After recording, it must be ensured that there is no clipping and no unwanted noise or sounds that could affect the detection algorithm. Below is an example clean recording of a laugh:</p>
			<a href="https://andrewkam.github.io/mumt307/source/laugh_copy.wav"><img src="images/waveformorig.jpg" width="708" height="127" alt=""/></a>
			<h3>Pitch Shift / Time Stretching</h3>
			<p>In order to simulate a crowd of laughs, the single laugh is duplicated into multiple streams. The number of streams is configurable. After duplication, each stream is pitch-shifted to a random level, within a range. This is in order to construct a variety of different voices with different tones, both lower and higher. Although this doesn't exactly simulate male and female voices very accurately, it is a rough estimation. The pitch-shifted streams are also time-stretched in order to maintain the same length is the original stream. Both these processes are completed using an implementation of a phase vocoder.</p>
  			<p>The phase vocoder performs a short-time FFT and then an inverse short-time FFT. In order to time-stretch the signal, a larger hop size for the overlap-add operation in the synthesis section is used relative to the analysis section. This produces more samples at the output than the input. Thus, the signal can be pitch-shifted by playing it at a higher sampling rate, producing a higher pitch of the signal of equal length.</p>
  			<p>This phase vocoder implementation was taken from <a href="https://www.mathworks.com/help/audio/examples/pitch-shifting-and-time-dilation-using-a-phase-vocoder-in-matlab.html">Pitch Shifting and Time Dilation Using a Phase Vocoder in MATLAB</a>.</p>
	  		<h5>Vocoder Flow Diagram</h5>
		  	<img src="images/vocoder.jpg" width="650" height="149" alt=""/><br>
		  	<h5>MATLAB Code</h5>
		  	<img src="images/vocodercode.jpg" width="597" height="860" alt=""/>
		  	<h3>Silence Removal</h3>
		  	<p>Upon recording, there will inevitably by a short period of silence at the beginning of the audio file. This file needs to be detected and removed from the audio signal in order for the resulting laugh to be continuous in nature, as the silence could be mixed into the stream. This was completed using the 'TrimStart' extraction option of the <i>miraudio</i> operator in the <a href="https://www.jyu.fi/hytk/fi/laitokset/mutku/en/research/materials/mirtoolbox">MIRtoolbox</a> in MATLAB.</p>
   			<h5>MATLAB Code</h5>
   			<img src="images/silencecode.jpg" width="450" height="143" alt=""/><br>
   			<h5>Silence Detection</h5>
   			<figcaption>A plot of the initial segment of silence, produced using <i>mirsegment(...,'RMS')</i> in the MIRToolbox:</figcaption>
	  		<img src="images/silence.jpg" width="804" height="522" alt=""/>
	  		<h3>Segmentation</h3>
	  		<p>People have different and unique patterns of laughing. The temporal envelope of each laughing burst, or grain, varies for different people in the overall laughing stream. I attempt to mimic these variations by shuffling around the laughing bursts of each of the pitch-shifted streams. The onsets of each burst is calculated using the 'Valleys' option of the <i>mirpeaks</i> operator in the MIRtoolbox, after converting the signal into <i>mirenvelope</i> form. These onset indices are stored as indicators of the start of each segment. These are then used to randomly shuffle each segement of each stream. However, the last segment is left in its position, as it was found that altering this last laughing burst would cause the overall stream to end abruptly.</p>
	  		<p>The 'Valleys' functionality turned out to be a very good indicator for the laugh onsets. Although it is an estimate, the contours of my laugh, which produces very distinct bursts with and very short silences in between, made the onset detection quite easy. However, if the recorded laugh was more continuous in nature, this 'Valleys' detection may not work. In this case, a consonant detection algorithm may be required, perhaps using zero-crossing rate as an indicator of onsets.</p>
			<h5>MATLAB Code</h5>
			<img src="images/onsetcode.jpg" width="397" height="211" alt=""/><br>
			<h5>Valley Detection</h5>
			<img src="images/valleys.jpg" width="745" height="586" alt=""/><br>
			<h5>Resulting Segment Shuffle</h5>
			<figcaption>An example of four streams with shuffled bursts: (the silence in beginning is introduced later in the procedure)</figcaption>
			<img src="images/streams.jpg" width="1000" height="794" alt=""/><br>
			<h5>Combined Streams</h5>
		<img src="images/combinedstreams.jpg" width="694" height="618" alt=""/>
		<h3>Reverberation</h3>
		<p>In a sitcom taping with a live audience, a studio is used to contain both the live set, actors, and the crowd. Thus, the recording of laughter is completed in a medium to large sized room. In order to create the effect of this environment, the impulse response of an auditorium was downloaded from the <a href="http://www.openairlib.net">Open AIR Library</a>. The impulse recorded at <a href="http://www.openairlib.net/auralizationdb/content/central-hall-university-york">Central Hall (Section 3C)</a> was used after testing various other rooms. This impulse was then convolved with the laughter streams.</p>
			<h5>Central Hall, University of York</h5>
	  		<img src="images/auditorium1.jpg" width="602" height="400" alt=""/>
	  		<img src="images/auditorium2.jpg" width="563" height="400" alt=""/><br>
	  		<img src="images/impulse.jpg" width="494" height="400" alt=""/>
	  		<h3>Other Effects and Modifications</h3>
	  		<h5>Chorus</h5>
	  		<p>A chorus effect was applied to each laugh stream in order to create a richer overall sound. This was completed using the <i>audioexample.Chrous</i> method in the Audio System Toolbox in MATLAB. A delay of 0.05s and wet/dry ratio of 0.6 was found to be suitable.</p>
	  		<h5>Amplitude</h5>
	  		<p>The amplitudes of each stream was randomly varied in order to create the effect of louder and quieter voices.</p>
	  		<h5>Delay</h5>
	  		<p>Slight delays were randomly assigned to streams in order to increase the perception of multiple voices.</p>
	  	<h2>Results</h2>
	  	<p>The result of all the combined stream duplications, segmentation, and effects described above produced a very good laugh track. You will most likely laugh along.</p>
  	  	<img src="images/laughtrack.jpg" width="748" height="394" alt=""/>
  	  	<h2>Issues and Limitations</h2>
  	  	<p>Although many impulses were tested, the reverb added to the laugh track is still too strong. The clean version of the output is preferable in my point of view, as it sounds more similar to the laugh tracks used in television shows. Although those shows are recorded in studios of decently-sized rooms, the live audience laughter is most likely altered in production to reduce any reverb.</p>
  	  	<p>It was desired to modify the original audio to simulate the laughter of both male and female voices. It was found that pitch-shifting worked ok when decreasing the pitch, but increasing it of any great length only made my voice sound sqeaky. Altering a male voice to sound female, or vice versa, is very difficult, and pitch-shifting was not successful in doing so. However, since there are so many streams layered on top of each other, it is difficult to hear this limitation.</p>
  	  	<p>As previously mentioned, my the onsets of own laugh was easy to detect using the 'Valley' functionality. If a more continuous laugh is used, the onsets may not be successfully detected.</p>
  	  	<h2>Code</h2>
  	  	<p>A zip of all the MATLAB code, with impulse response file and sample audio input file can be downloaded <a href="https://andrewkam.github.io/mumt307/source/final_project_andrewkam.zip">here</a>.</p>
  	  	<h2>Execution Procedure</h2>
  	  	<p>Laugh synth can be run by calling the laughSynth function in MATLAB with the following parameters:<br><br>
  	  	&emsp;inputAudio = input audio filename<br>
		&emsp;sampleRate = sampling frequency<br>
		&emsp;streamCount = number of streams to create<br>
		&emsp;reverbFlag = 0 to disable reverb, 1 to enable reverb</p>
 	  	<p>For example, the following takes in the audio file 'laugh.wav' with sampling frequency 44100, creates 20 streams, does not add reverb, and returns an array containing the resulting laugh track signal:<br><br>
 	  	&emsp;outputAudio = laughSynth('laugh.wav', 44100, 20, 0);</p>
 	  	<p>The ouput audio array can be played using the soundsc function, or any other function that plays audio from an array. The file <a href="https://andrewkam.github.io/mumt307/source/IRauditorium.wav">IRauditorium.wav</a> is required to be in the same directory in order to add reverb.</p>
 	  	<p>A sample input audio laugh file can be downloaded <a href="https://andrewkam.github.io/mumt307/source/laugh.wav">here</a>.</p>
  	  	<h2>References</h2>
  	  	<p>Armstrong, Jennifer Keishin. 2016. "Where Does Canned Laughter Come From - And Where Did It Go?" Last modified 26 September 2016. http://www.bbc.com/culture/story/20160926-where-does-canned-laughter-come-from-and-where-did-it-go.</p>
  	  	<p>MathWorks. "Pitch Shifting and Time Dilation Using a Phase Vocoder in MATLAB." https://www.mathworks.com/help/audio/examples/pitch-shifting-and-time-dilation-using-a-phase-vocoder-in-matlab.html.</p>
  	  	<p>Open Acoustic Impulse Response (Open AIR) Library. "Central Hall, University of York." http://www.openairlib.net/auralizationdb/content/central-hall-university-york.</p>
  	  	<p>University of Jyväskylä. "MIRtoolbox." Last modified 11 February 2018. https://www.jyu.fi/hytk/fi/laitokset/mutku/en/research/materials/mirtoolbox.</p>
    </ul>
    
	</section>
  <!-- Copyrights Section -->
  <!-- <div class="copyright">&copy;2015 - <strong>Light Theme</strong></div> -->
</div>
<!-- Main Container Ends -->
</body>
</html>
